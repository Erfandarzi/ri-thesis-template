Automatically generated by Mendeley Desktop 1.13.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Chen2011,
author = {Chen, David L and Mooney, Raymond J},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/Chen, Mooney - 2011 - Learning to Interpret Natural Language Navigation Instructions from Observations.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{Learning to Interpret Natural Language Navigation Instructions from Observations}},
year = {2011}
}
@phdthesis{Tellex2010,
author = {Tellex, Stefanie},
file = {:home/fduvalle/proj/mendeley/papers/Tellex - 2010 - Natural Language and Spatial Reasoning.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
number = {2002},
school = {Massachusetts Institute of Technology},
title = {{Natural Language and Spatial Reasoning}},
year = {2010}
}
@article{Levit2007,
abstract = {We have developed components of an automated system that understands and follows navigational instructions. The system has prior knowledge of the geometry and landmarks of specific maps. This knowledge is exploited to infer complex paths through maps based on natural language descriptions. The approach is based on an analysis of verbal commands in terms of elementary semantic units that are composed to generate a probability distribution over possible spatial paths in a map. An integration mechanism based on dynamic programming guides this language-to-path translation process, ensuring that resulting paths satisfy continuity and smoothness criteria. In the current implementation, parsing of text into semantic units is performed manually. Composition and interpretation of semantic units into spatial paths is performed automatically. In the evaluations, we show that the system accurately predicts the speakers' intended meanings for a range of instructions. This paper provides building blocks for a complete system that, when combined with robust parsing technologies, could lead to a fully automatic spatial language interpretation system.},
author = {Levit, Michael and Roy, Deb},
file = {:home/fduvalle/proj/mendeley/papers/Levit, Roy - 2007 - Interpretation of spatial language in a map navigation task.pdf:pdf},
institution = {BBN Technologies, Cambridge, MA 02138, USA.},
journal = {Systems, Man, and Cybernetics},
keywords = {algorithms,artificial intelligence,automated,automated methods,controlled,geographic information systems,language,man machine systems,movement,natural language processing,nlmmp,pattern recognition,user computer interface,vocabulary},
mendeley-tags = {nlmmp},
pmid = {17550120},
title = {{Interpretation of spatial language in a map navigation task.}},
year = {2007}
}
@inproceedings{Simeonov2011,
author = {Simeonov, Dimitar and Tellex, Stefanie and Kollar, Thomas and Roy, Nicholas},
booktitle = {Workshop on Grounding Human-Robot Dialog for Spatial Tasks},
file = {:home/fduvalle/proj/mendeley/papers/Simeonov et al. - 2011 - Toward Interpreting Spatial Language Discourse with Grounding Graphs.pdf:pdf},
title = {{Toward Interpreting Spatial Language Discourse with Grounding Graphs}},
year = {2011}
}
@article{Lauria2002,
abstract = {How will naive users program domestic robots? This paper describes the design of a practical system that uses natural language to teach a vision-based robot how to navigate in a miniature town. To enable unconstrained speech the robot is provided with a set of primitive procedures derived from a corpus of route instructions. When the user refers to a route that is not known to the robot, the system will learn it by combining primitives as instructed by the user. This paper describes the components of the Instruction-Based Learning architecture and discusses issues of knowledge representation, the selection of primitives and the conversion of natural language into robot-understandable procedures. (C) 2002 Published by Elsevier Science B.V.},
author = {Lauria, Stanislao and Bugmann, Guido and Kyriacou, Theocharis and Klein, Ewan},
file = {:home/fduvalle/proj/mendeley/papers/Lauria et al. - 2002 - Mobile robot programming using natural language.pdf:pdf},
journal = {Robotics and Autonomous Systems},
keywords = {corpus collection,human robot dialogue,mobile robots learning,natural language,nlmmp,route},
mendeley-tags = {nlmmp},
publisher = {Elsevier},
title = {{Mobile robot programming using natural language}},
year = {2002}
}
@inproceedings{Howard2014a,
author = {Howard, Thomas M and Chung, Istvan and Propp, Oron and Walter, Matthew R and Roy, Nicholas},
booktitle = {IROS Workshop on Rehabilitation and Assistive Robotics},
file = {:home/fduvalle/proj/mendeley/papers/Howard et al. - 2014 - Efficient Natural Language Interfaces for Assistive Robots.pdf:pdf},
title = {{Efficient Natural Language Interfaces for Assistive Robots}},
year = {2014}
}
@inproceedings{Kress-Gazit2007,
abstract = {Recently, Linear Temporal Logic (LTL) has been successfully applied to high-level task and motion planning problems for mobile robots. One of the main attributes of LTL is its close relationship with fragments of natural language. In this paper, we take the first steps toward building a natural language interface for LTL planning methods with mobile robots as the application domain. For this purpose, we built a structured English language which maps directly to a fragment of LTL.},
author = {Kress-Gazit, Hadas and Fainekos, Georgios E. and Pappas, George J.},
booktitle = {International Conference on Intelligent Robots and Systems},
file = {:home/fduvalle/proj/mendeley/papers/Kress-Gazit, Fainekos, Pappas - 2007 - From structured english to robot motion.pdf:pdf},
title = {{From structured english to robot motion}},
year = {2007}
}
@article{Thrun2004b,
author = {Thrun, Sebastian},
file = {:home/fduvalle/proj/mendeley/papers/Thrun - 2004 - Toward a Framework for Human-Robot Interaction.pdf:pdf},
journal = {Human-Computer Interaction},
title = {{Toward a Framework for Human-Robot Interaction}},
year = {2004}
}
@inproceedings{Grubb2011,
author = {Grubb, Alexander and Duvallet, Felix and Tellex, Stefanie and Kollar, Thomas and Roy, Nicholas and Stentz, Anthony and Bagnell, J. Andrew},
booktitle = {ICML Workshop on New Developments in Imitation Learning},
file = {:home/fduvalle/proj/mendeley/papers/Grubb et al. - 2011 - Imitation Learning for Natural Language Direction Following.pdf:pdf},
title = {{Imitation Learning for Natural Language Direction Following}},
year = {2011}
}
@article{Wei2009,
abstract = {An important component of human-robot interaction is that people need to be able to instruct robots to move to other locations using naturally given directions. When giving directions, people often make mistakes such as labelling errors (e.g., left vs. right) and errors of omission (skipping important decision points in a sequence). Furthermore, people often use multiple levels of granularity in specifying directions, referring to locations using single object landmarks, multiple landmarks in a given location, or identifying large regions as a single location. The challenge is to identify the correct path to a destination from a sequence of noisy, possibly erroneous directions. In our work we cast this problem as probabilistic inference: given a set of directions, an agent should automatically find the path with the geometry and physical appearance to maximize the likelihood of those directions. We use a specific variant of a Markov Random Field (MRF) to represent our model, and gather multi-granularity representation information using existing large tagged datasets. On a dataset of route directions collected in a large third floor university building, we found that our algorithm correctly inferred the true final destination in 47 out of the 55 cases successfully followed by humans volunteers. These results suggest that our algorithm is performing well relative to human users. In the future this work will be included in a broader system for autonomously constructing environmental representations that support natural human-robot interaction for direction giving.},
author = {Wei, Yuan and Brunskill, Emma and Kollar, Thomas and Roy, Nicholas},
file = {:home/fduvalle/proj/mendeley/papers/Wei et al. - 2009 - Where to go Interpreting natural directions using global inference.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation (2009)},
keywords = {a dataset photographs,analyzing tags,directions,flickr,labels,nlmmp,shared probabilities between different,specific dataset we,such,types objects,use,users,we can automatically compute,which tagged with},
mendeley-tags = {nlmmp},
pages = {3761--3767},
publisher = {Ieee},
title = {{Where to go: Interpreting natural directions using global inference}},
year = {2009}
}
@article{Skantze2005,
abstract = {In this study, an explorative experiment was conducted in which subjects were asked to give route directions to each other in a simulated campus (similar to Map Task). In order to elicit error handling strategies, a speech recogniser was used to corrupt the speech in one direction. This way, data could be collected on how the subjects might recover from speech recognition errors. This method for studying error handling has the advantages that the level of understanding is transparent to the analyser, and the errors that occur are similar to errors in spoken dialogue systems. The results show that when subjects face speech recognition problems, a common strategy is to ask task-related questions that confirm their hypothesis about the situation instead of signalling non-understanding. Compared to other strategies, such as asking for a repetition, this strategy leads to better understanding of subsequent utterances, whereas signalling non-understanding leads to decreased experience of task success. (c) 2005 Elsevier B.V. All rights reserved.},
author = {Skantze, G},
file = {:home/fduvalle/proj/mendeley/papers/Skantze - 2005 - Exploring human error recovery strategies Implications for spoken dialogue systems.pdf:pdf},
journal = {Speech Communication},
pages = {325--341},
title = {{Exploring human error recovery strategies: Implications for spoken dialogue systems}},
volume = {45},
year = {2005}
}
@inproceedings{Matuszek2012,
author = {Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter},
booktitle = {International Symposium on Experimental Robotics},
file = {:home/fduvalle/proj/mendeley/papers/Matuszek et al. - 2012 - Learning to Parse Natural Language Commands to a Robot Control System.pdf:pdf},
title = {{Learning to Parse Natural Language Commands to a Robot Control System}},
year = {2012}
}
@inproceedings{Macmahon2006,
author = {MacMahon, Matthew and Stankiewicz, Brian and Kuipers, Benjamin},
booktitle = {National Conference on Artificial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/MacMahon, Stankiewicz, Kuipers - 2006 - Walk the Talk Connecting Language, Knowledge, and Action in Route Instructions.pdf:pdf},
keywords = {integrated intelligent capabilities,nlmmp,special track},
mendeley-tags = {nlmmp},
title = {{Walk the Talk: Connecting Language, Knowledge, and Action in Route Instructions}},
year = {2006}
}
@inproceedings{Williams2013,
author = {Williams, Tom and Cantrell, Rehj and Briggs, Gordon and Schermerhorn, Paul and Scheutz, Matthias},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/Williams et al. - 2013 - Grounding Natural Language References to Unvisited and Hypothetical Locations.pdf:pdf},
title = {{Grounding Natural Language References to Unvisited and Hypothetical Locations}},
year = {2013}
}
@inproceedings{Rudnicky1993,
author = {Rudnicky, Alexander I.},
booktitle = {Proceedings of the Workshop on Human Language Technology},
file = {:home/fduvalle/proj/mendeley/papers/Rudnicky - 1993 - Mode preference in a simple data-retrieval task.pdf:pdf},
title = {{Mode preference in a simple data-retrieval task}},
year = {1993}
}
@phdthesis{Macmahon2007,
author = {MacMahon, Matthew},
file = {:home/fduvalle/proj/mendeley/papers/MacMahon - 2007 - Following Natural Language Route Instructions.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
school = {University of Texas at Austin},
title = {{Following Natural Language Route Instructions}},
year = {2007}
}
@article{Harnad1990,
author = {Harnad, Stevan},
file = {:home/fduvalle/proj/mendeley/papers/Harnad - 1990 - The Symbol Grounding Problem(2).pdf:pdf},
journal = {Physica D: Nonlinear Phenomena},
title = {{The Symbol Grounding Problem}},
year = {1990}
}
@inproceedings{Branavan2010,
abstract = {The function of the immune system peaks at around puberty and gradually declines thereafter with advance in age. The age-related decline of immunological function primarily occurs in the T cell-dependent immune system and is generally associated with increase in susceptibility to infections as well as in incidence of autoimmune phenomena in the elderly. The age-related change in T cell-dependent immune functions can be ascribed to the physiological thymic atrophy which starts in an early stage of life. Emigration of T cells from the thymus to the periphery mainly takes place in the late fetal and newborn stage, and dramatically declines after puberty. In other words, the thymic capacity to promote T cell differentiation starts to change in the early stage of life in terms of quantity and quality of T cells. Thus, the composition of T cell-subsets in the periphery gradually changes with age, resulting in the alteration of T cell functions in the elderly. The restoration of immunological functions of the aged individuals is possible and might be beneficial for them to cope with various diseases associated with aging. Physiological thymic atrophy is controlled by both extrathymic and intrathymic factors, and is not a totally irreversible process. The process of thymic atrophy might be explained by further understanding of the relationship between the neuroendocrine and the immune systems.},
author = {Branavan, S R K and Zettlemoyer, Luke and Barzilay, Regina},
booktitle = {Association for Computational Linguistics},
file = {:home/fduvalle/proj/mendeley/papers/Branavan, Zettlemoyer, Barzilay - 2010 - Reading Between the Lines Learning to Map High-level Instructions to Commands.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
pmid = {1449050},
title = {{Reading Between the Lines: Learning to Map High-level Instructions to Commands}},
year = {2010}
}
@inproceedings{Andreas2014,
author = {Andreas, Jacob and Klein, Dan},
booktitle = {Conference on Natural Language Learning},
file = {:home/fduvalle/proj/mendeley/papers/Andreas, Klein - 2014 - Grounding Language with Points and Paths in Continuous Spaces.pdf:pdf},
title = {{Grounding Language with Points and Paths in Continuous Spaces}},
year = {2014}
}
@inproceedings{Blaylock2009,
author = {Blaylock, Nate and Swain, Bradley and Allen, James},
booktitle = {ACM SIGSPATIAL GIS International Workshop on Querying and Mining Uncertain Spatio-Temporal Data},
file = {:home/fduvalle/proj/mendeley/papers/Blaylock, Swain, Allen - 2009 - Mining Geospatial Path Data from Natural Language Descriptions.pdf:pdf},
keywords = {geospatial language understanding,information extraction,nlmmp},
mendeley-tags = {nlmmp},
title = {{Mining Geospatial Path Data from Natural Language Descriptions}},
year = {2009}
}
@inproceedings{Kollar2010a,
abstract = {Speaking using unconstrained natural language is an intuitive and flexible way for humans to interact with robots. Understanding this kind of linguistic input is challenging because diverse words and phrases must be mapped into structures that the robot can understand, and elements in those structures must be grounded in an uncertain environment. We present a system that follows natural language directions by extracting a sequence of spatial description clauses from the linguistic input and then infers the most probable path through the environment given only information about the environmental geometry and detected visible objects. We use a probabilistic graphical model that factors into three key components. The first component grounds landmark phrases such as "the computers" in the perceptual frame of the robot by exploiting co-occurrence statistics from a database of tagged images such as Flickr. Second, a spatial reasoning component judges how well spatial relations such as "past the computers" describe a path. Finally, verb phrases such as "turn right" are modeled according to the amount of change in orientation in the path. Our system follows 60\% of the directions in our corpus to within 15 meters of the true destination, significantly outperforming other approaches.},
author = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},
booktitle = {International Conference on Human-Robot Interaction},
file = {:home/fduvalle/proj/mendeley/papers/Kollar et al. - 2010 - Toward Understanding Natural Language Directions.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{Toward Understanding Natural Language Directions}},
year = {2010}
}
@inproceedings{Cantrell2010,
author = {Cantrell, Rehj and Scheutz, Matthias and Schermerhorn, Paul and Wu, Xuan},
booktitle = {Human-Robot Interaction},
file = {:home/fduvalle/proj/mendeley/papers/Cantrell et al. - 2010 - Robust spoken instruction understanding for HRI.pdf:pdf},
keywords = {-natural human-robot interaction,dialogue interactions,integrated architecture,natural language,processing},
title = {{Robust spoken instruction understanding for HRI}},
year = {2010}
}
@article{Kress-Gazit2008,
author = {Kress-Gazit, Hadas and Fainekos, Georgios E. and Pappas, George J.},
file = {:home/fduvalle/proj/mendeley/papers/Kress-Gazit, Fainekos, Pappas - 2008 - Translating Structured English to Robot Controllers.pdf:pdf},
journal = {Advanced Robotics},
keywords = {motion planning,structured english,task planning,temporal logic},
title = {{Translating Structured English to Robot Controllers}},
year = {2008}
}
@article{Muller2000,
abstract = {This work is about the integration of the skills robot control, landmark recognition,and qualitative reasoning in a single autonomous mobile system. It deals with the transfer of coarse qualitative route de- scriptions usually given by humans into the domain of mobile robot nav- igation. An approach is proposed that enables the Bremen Autonomous Wheelchair to followa route in a building, based on a description such as “Followthis corridor, take the second corridor branching off on the right-hand side and stop at its end.” The landmark recognition uses a newmethod taken from the field of image processing for detecting sig- nificant places along a route.},
author = {M\"{u}ller, R and R\"{o}fer, T and Lankenau, Axel and Musto, A and Stein, K and A},
file = {:home/fduvalle/proj/mendeley/papers/M\"{u}ller et al. - 2000 - Coarse qualitative descriptions in robot navigation.pdf:pdf},
journal = {Spatial Cognition II},
title = {{Coarse qualitative descriptions in robot navigation}},
year = {2000}
}
@phdthesis{Winograd1971,
author = {Winograd, Terry},
file = {:home/fduvalle/proj/mendeley/papers/Winograd - 1971 - Procedures as a Representation for Data in a Computer Program for Understanding Natural Language.pdf:pdf},
school = {Massachusetts Institute of Technology},
title = {{Procedures as a Representation for Data in a Computer Program for Understanding Natural Language}},
year = {1971}
}
@article{Richter2010,
abstract = {Automated route guidance systems, both web-based systems and en-route systems, have become commonplace in recent years. These systems often replace human-generated directions, which are often incomplete, vague, or in error. However, human-generated directions have the ability to differentiate between easy and complex steps through language in a way that is more difficult in automated systems. This article examines a set of human-generated verbal directions to better understand why some parts of directions are perceived as being more difficult than the remaining steps. Insights from this analysis will lead to recommendations to improve the next generation of automated route guidance systems.},
author = {Richter, Kai-Florian and Hirtle, Stephen and Srinivas, Samvith and Firth, Robert},
file = {:home/fduvalle/proj/mendeley/papers/Richter et al. - 2010 - This is the tricky part When directions become difficult.pdf:pdf},
journal = {Journal of Spatial Information Science},
number = {1},
pages = {53--73},
title = {{This is the tricky part: When directions become difficult}},
volume = {1},
year = {2010}
}
@article{Simmons2003,
author = {Simmons, Reid and Goldberg, Dani and Goode, Adam and Montemerlo, Michael and Roy, Nicholas and Sellner, Brennan and Urmson, Chris and Schultz, Alan and Abramson, Myriam and Adams, William and Atrash, Amin and Bugajska, Magda and Coblenz, Michael and MacMahon, Matthew and Perzanowski, Dennis and Horswill, Ian and Zubek, Robert and Kortenkamp, David and Wolfe, Bryn and Milam, Tod and Maxwell, Bruce},
file = {:home/fduvalle/proj/mendeley/papers/Simmons et al. - 2003 - GRACE An Autonomous Robot for the AAAI Robot Challenge.pdf:pdf},
journal = {AAAI Magazine},
keywords = {human-robot interaction,localization and mapping,robot competition,robotics},
title = {{GRACE: An Autonomous Robot for the AAAI Robot Challenge}},
year = {2003}
}
@misc{Chiang2006,
author = {Chiang, David},
booktitle = {Tutorial on ACL06},
file = {:home/fduvalle/proj/mendeley/papers/Chiang - 2006 - An Introduction to Synchronous Grammars.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{An Introduction to Synchronous Grammars}},
year = {2006}
}
@article{Talmy2005,
abstract = {Linguistic Research to date has determined many of the factors that govern the structure of the spatial schemas found across spoken languages. We can now inte- grate these factors and propose the comprehensive system they comprise for spa- tial structuring in language.This system is characterized by several features. At a componential level, it has a relatively closed universally available inventory of fundamental spatial elements. These elements group into a relatively closed set of spatial categories. And each category includes only a relatively closed small num- ber of particular elements:the spatial distinctions that each category can ever mark. At a composite level, elements of the inventory combine in particular ar- rangements to form whole spatial schemas.Each language has a relatively closed set of \"{y}pre-packagedþ schemas of this sort. Finally, the system includes a set of properties that can generalize and processes that can extend or deform pre- packaged schemas and thus enable a language\'{y}s particular set of schemas to be applied to a wider range of spatial structures.},
author = {Talmy, Leonard},
file = {:home/fduvalle/proj/mendeley/papers/Talmy - 2005 - The fundamental system of spatial schemas in language.pdf:pdf},
journal = {From Perception to Meaning: Image Schemas in Cognitive Linguistics},
keywords = {spatial primitives,spatial schema,spatial structure},
title = {{The fundamental system of spatial schemas in language}},
year = {2005}
}
@article{Bauer2009,
author = {Bauer, Andrea and Klasing, Klaas and Lidoris, Georgios and M\"{u}hlbauer, Quirin and Rohrm\"{u}ller, Florian and Sosnowski, Stefan and Xu, Tingting and K\"{u}hnlenz, Kolja and Wollherr, Dirk and Buss, Martin},
file = {:home/fduvalle/proj/mendeley/papers/Bauer et al. - 2009 - The Autonomous City Explorer Towards Natural Human-Robot Interaction in Urban Environments.pdf:pdf},
journal = {International Journal of Social Robotics},
keywords = {autonomous outdoor navigation,field robotics,human-robot interaction,knowledge,representation,social robotics},
title = {{The Autonomous City Explorer: Towards Natural Human-Robot Interaction in Urban Environments}},
year = {2009}
}
@article{Miller1990,
abstract = {WordNet is an on-line lexical reference system whose design is inspired by current},
author = {Miller, George},
journal = {International Journal of Lexicography},
title = {{WordNet: An on-line lexical database}},
year = {1990}
}
@inproceedings{Tenorth2010,
author = {Tenorth, M and Nyga, D and Beetz, M},
booktitle = {International Conference on Robotics and Automation},
file = {:home/fduvalle/proj/mendeley/papers/Tenorth, Nyga, Beetz - 2010 - Understanding and executing instructions for everyday manipulation tasks.pdf:pdf},
title = {{Understanding and executing instructions for everyday manipulation tasks}},
year = {2010}
}
@inproceedings{Huang2010,
abstract = {Natural language is a flexible and intuitive modality for conveying directions and commands to a robot but presents a number of computational challenges. Diverse words and phrases must be mapped into structures that the robot can understand, and elements in those structures must be grounded in an uncertain environment. In this paper we present a micro-air vehicle (MAV) capable of following natural language directions through a previously mapped and labeled environment. We extend our previous work in understanding 2D natural language directions to three dimensions, accommodating new verb modifiers such as go up and go down, and commands such as turn around and face the windows. We demonstrate the robot following directions created by a human for another human, and interactively executing commands in the context of surveillance and search and rescue in confined spaces. In an informal study, 71\% of the paths computed from directions given by one user terminated within 10m of the desired destination.},
author = {Huang, Albert S and Tellex, Stefanie and Bachrach, Abraham and Kollar, Thomas and Roy, Deb and Roy, Nicholas},
booktitle = {International Conference on Intelligent Robots and Systems},
file = {:home/fduvalle/proj/mendeley/papers/Huang et al. - 2010 - Natural Language Command of an Autonomous Micro-Air Vehicle.pdf:pdf},
keywords = {aerial robotics,navigation,nlmmp,physical human robot interaction},
mendeley-tags = {nlmmp},
title = {{Natural Language Command of an Autonomous Micro-Air Vehicle}},
year = {2010}
}
@techreport{MacGlashan2014b,
author = {MacGlashan, James and Babes-Vroman, Monica and DesJardins, Marie and Littman, Michael and Muresan, Smaranda and Squire, Shawn},
file = {:home/fduvalle/proj/mendeley/papers/MacGlashan et al. - 2014 - Translating English to Reward Functions.pdf:pdf},
institution = {Computer Science Department Brown University},
title = {{Translating English to Reward Functions}},
year = {2014}
}
@inproceedings{Tellex2011,
author = {Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven and Walter, Matthew R and Banerjee, Ashis Gopal and Teller, Seth and Roy, Nicholas},
booktitle = {National Conference on Artiﬁcial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/Tellex et al. - 2011 - Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation}},
year = {2011}
}
@article{Hemachandra2011,
author = {Hemachandra, Sachithra and Kollar, Thomas and Roy, Nicholas and Teller, Seth},
file = {:home/fduvalle/proj/mendeley/papers/Hemachandra et al. - 2011 - Following and interpreting narrated guided tours.pdf:pdf},
journal = {International Conference on Robotics and Automation},
publisher = {Ieee},
title = {{Following and interpreting narrated guided tours}},
year = {2011}
}
@inproceedings{Kollar2009,
author = {Kollar, Thomas and Roy, Nicholas},
booktitle = {International Conference on Robotics and Automation},
file = {:home/fduvalle/proj/mendeley/papers/Kollar, Roy - 2009 - Utilizing object-object and object-scene context when planning to find things.pdf:pdf},
title = {{Utilizing object-object and object-scene context when planning to find things}},
year = {2009}
}
@inproceedings{Matuszek2010,
author = {Matuszek, Cynthia and Fox, Dieter and Koscher, Karl},
booktitle = {Human-Robot Interaction},
file = {:home/fduvalle/proj/mendeley/papers/Matuszek, Fox, Koscher - 2010 - Following directions using statistical machine translation.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{Following directions using statistical machine translation}},
year = {2010}
}
@inproceedings{Fasola2013,
author = {Fasola, Juan and Mataric, Maja J},
booktitle = {International Symposium on Robot and Human Interactive Communication},
file = {:home/fduvalle/proj/mendeley/papers/Fasola, Mataric - 2013 - Modeling dynamic spatial relations with global properties for natural language-based human-robot interaction.pdf:pdf},
title = {{Modeling dynamic spatial relations with global properties for natural language-based human-robot interaction}},
year = {2013}
}
@inproceedings{Dzifcak2009,
abstract = {Robots that can be given instructions in spoken language need to be able to parse a natural language utterance quickly, determine its meaning, generate a goal representation from it, check whether the new goal conflicts with existing goals, and if acceptable, produce an action sequence to achieve the new goal (ideally being sensitive to the existing goals). In this paper, we describe an integrated robotic architecture that can achieve the above steps by translating natural language instructions incrementally and simultaneously into formal logical goal description and action languages, which can be used both to reason about the achievability of a goal as well as to generate new action scripts to pursue the goal. We demonstrate the implementation of our approach on a robot taking spoken natural language instructions in an office environment.},
author = {Dzifcak, Juraj and Scheutz, Matthias and Baral, Chitta and Schermerhorn, Paul},
booktitle = {International Conference on Robotics and Automation},
file = {:home/fduvalle/proj/mendeley/papers/Dzifcak et al. - 2009 - What to do and how to do it Translating natural language directives into temporal and dynamic logic representati.pdf:pdf},
title = {{What to do and how to do it: Translating natural language directives into temporal and dynamic logic representation for goal management and action execution}},
year = {2009}
}
@inproceedings{Macglashan2014a,
author = {Macglashan, James and Littman, Michael and Loftin, Robert and Peng, Bei and Roberts, David and Taylor, Matthew E},
booktitle = {AAAI Machine Learning for Interactive Systems Workshop},
file = {:home/fduvalle/proj/mendeley/papers/Macglashan et al. - 2014 - Training an Agent to Ground Commands with Reward and Punishment.pdf:pdf},
keywords = {AAAI Technical Report WS-14-07},
title = {{Training an Agent to Ground Commands with Reward and Punishment}},
year = {2014}
}
@inproceedings{Landsiedel2013,
abstract = {This paper presents an approach to combine automatic semantic place labeling of robot-generated maps with reasoning on human route descriptions. Enabling robots to understand human route descriptions can simplify HRI situations in household or industrial settings. However, solving this problem requires handling the ambiguity present in route descriptions and the possible unreliability of the semantic perception capabilities of the robot. We address this problem by absorbing these uncertainties in a probability distribution measuring the likelihood of the different interpretations (paths) of a given route description and selecting its MAP solution. The approach is evaluated on a dataset of route descriptions transcribed into a suitable representation using standard information retrieval metrics. These performance measurements indicate that the method can correctly interpret route descriptions even in challenging environments.},
author = {Landsiedel, Christian and {De Nijs}, Roderick and Kuhnlenz, Kolja and Wollherr, Dirk and Buss, Martin},
booktitle = {International Conference on Robotics and Automation},
file = {:home/fduvalle/proj/mendeley/papers/Landsiedel et al. - 2013 - Route description interpretation on automatically labeled robot maps.pdf:pdf},
title = {{Route description interpretation on automatically labeled robot maps}},
year = {2013}
}
@inproceedings{Vogel2010,
author = {Vogel, Adam and Jurafsky, Dan},
booktitle = {Association for Computational Linguistics},
editor = {{Association For Computational Linguistics}},
file = {:home/fduvalle/proj/mendeley/papers/Vogel, Jurafsky - 2010 - Learning to Follow Navigational Directions.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
publisher = {Association for Computational Linguistics},
title = {{Learning to Follow Navigational Directions}},
year = {2010}
}
@inproceedings{Misra2014,
author = {Misra, Dipendra K and Sung, Jaeyong and Lee, Kevin and Saxena, Ashutosh},
booktitle = {Robotics: Science and Systems},
file = {:home/fduvalle/proj/mendeley/papers/Misra et al. - 2014 - Tell Me Dave Context-Sensitive Grounding of Natural Language to Manipulation Instructions.pdf:pdf},
title = {{Tell Me Dave: Context-Sensitive Grounding of Natural Language to Manipulation Instructions}},
year = {2014}
}
@inproceedings{Mandel2006,
abstract = {This paper describes the use of natural language route descriptions in the mobile robot navigation domain. Guided by corpus analysis and earlier work on coarse qualitative route descriptions, we decompose instructions given by humans into sequences of imprecise route segment descriptions. By applying fuzzy rules for the involved spatial relations and actions, we construct a search tree that can be searched in a depth-first branch-and-bound manner for the most probable goal configuration w.r.t. the global workspace knowledge of the robot. The applicability of our approach is shown by a real-world experiment where an operator instructs his automated wheelchair to navigate in an office-like environment},
author = {Mandel, Christian and Frese, Udo and Ro̊fer, Thomas},
booktitle = {International Conference on Intelligent Robots and Systems},
file = {:home/fduvalle/proj/mendeley/papers/Mandel, Frese, Ro̊fer - 2006 - Robot navigation based on the mapping of coarse qualitative route descriptions to route graphs.pdf:pdf},
title = {{Robot navigation based on the mapping of coarse qualitative route descriptions to route graphs}},
year = {2006}
}
@inproceedings{Mooney2008,
annote = {Goal: system that learns *both* language and perception at the same time.},
author = {Mooney, Raymond J},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/Mooney - 2008 - Learning to Connect Language and Perception.pdf:pdf},
title = {{Learning to Connect Language and Perception}},
year = {2008}
}
@article{Agre1990,
author = {Agre, Philip E and Chapman, David},
file = {:home/fduvalle/proj/mendeley/papers/Agre, Chapman - 1990 - What are plans for.pdf:pdf},
journal = {Robotics and Autonomous Systems},
title = {{What are plans for?}},
year = {1990}
}
@article{Landau1993,
abstract = {Fundamental to spatial knowledge in all species are the representations underlying object recognition, object search, and navigation through space. But what sets humans apart from other species is our ability to express spatial experience through language. This target article explores the language of objects and places, asking what geometric properties are preserved in the representations underlying object nouns and spatial prepositions in English. Evidence from these two aspects of language suggests there are significant differences in the geometric richness with which objects and places are encoded. When an object is named (i.e., with count nouns), detailed geometric properties principally the object's shape (axes, solid and hollow volumes, surfaces, and parts) are represented. In contrast, when an object plays the role of either figure (located object) or ground (reference object) in a locational expression, only very coarse geometric object properties are represented, primarily the main axes. In addition, the spatial functions encoded by spatial prepositions tend to be nonmetric and relatively coarse, for example, containment, contact, relative distance, and relative direction. These properties are representative of other languages as well. The striking differences in the way language encodes objects versus places lead us to suggest two explanations: First, there is a tendency for languages to level out geometric detail from both object and place representations. Second, a nonlinguistic disparity between the representations of what and where underlies how language represents objects and places. The language of objects and places converges with and enriches our understanding of corresponding spatial representations.},
author = {Landau, Barbara and Jackendoff, Ray},
file = {:home/fduvalle/proj/mendeley/papers/Landau, Jackendoff - 1993 - What and where in spatial language and spatial cognition.pdf:pdf},
journal = {Behavioral and Brain Sciences},
publisher = {Cambridge University Press},
title = {{What and where in spatial language and spatial cognition}},
year = {1993}
}
@inproceedings{Branavan2009,
abstract = {In this paper, we present a reinforcement learning approach for mapping natural language instructions to sequences of executable actions. We assume access to a reward function that defines the quality of the executed actions. During training, the learner repeatedly constructs action sequences for a set of documents, executes those actions, and observes the resulting reward. We use a policy gradient algorithm to estimate the parameters of a log-linear model for action selection. We apply our method to interpret instructions in two domains Windows troubleshooting guides and game tutorials. Our results demonstrate that this method can rival supervised learning techniques while requiring few or no annotated training examples.},
author = {Branavan, S R K and Chen, Harr and Zettlemoyer, Luke and Barzilay, Regina},
booktitle = {International Joint Conference on Natural Language Processing},
file = {:home/fduvalle/proj/mendeley/papers/Branavan et al. - 2009 - Reinforcement learning for mapping instructions to actions.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
pmid = {18493666},
title = {{Reinforcement learning for mapping instructions to actions}},
year = {2009}
}
@inproceedings{Howard2014,
author = {Howard, Thomas M. and Tellex, Stefanie and Roy, Nicholas},
booktitle = {International Conference on Robotics and Automation},
file = {:home/fduvalle/proj/mendeley/papers/Howard, Tellex, Roy - 2014 - A natural language planner interface for mobile manipulators.pdf:pdf},
title = {{A natural language planner interface for mobile manipulators}},
year = {2014}
}
@book{Fellbaum1998,
abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
author = {Fellbaum, Christiane},
pmid = {21561289},
series = {Language, Speech, and Communication},
title = {{WordNet: An Electronic Lexical Database}},
year = {1998}
}
@inproceedings{MacMahon2005,
author = {MacMahon, Matthew},
booktitle = {AAAI Workshop on Modular Construction of Human-like Intelligence},
file = {:home/fduvalle/proj/mendeley/papers/MacMahon - 2005 - MARCO A Modular Architecture for Following Route Instructions.pdf:pdf},
title = {{MARCO: A Modular Architecture for Following Route Instructions}},
year = {2005}
}
@book{Jackendoff1983,
abstract = {This book emphasizes the role of semantics as a bridge between the theory of language and the theories of other cognitive capacities such as visual perception and motor control. It develops the position that the study of semantics of natural language is the study of the structure of thought, and that grammatical structure offers a much more important source of evidence for the theory of cognition than is often supposed by linguists, philosophers, psychologists, or computer scientists.Ray Jackendoff is Professor of Linguistics and Chairman of the Linguistics and Cognitive Science Program at Brandeis University. His most recent book, coauthored with Fred Lerdahl, is A Generative Theory of Tonal Music (MIT Press paperback). Semantics and Cognition is included in the series, Current Studies in Linguistics.},
author = {Jackendoff, Ray},
pmid = {2349344},
title = {{Semantics and Cognition}},
year = {1983}
}
@article{Ochsman1974,
author = {Ochsman, Robert B and Chapanis, Alphonse},
file = {:home/fduvalle/proj/mendeley/papers/Ochsman, Chapanis - 1974 - The effects of 10 communication modes on the behavior of teams during co-operative problem-solving.pdf:pdf},
journal = {International Journal of Man-Machine Studies},
title = {{The effects of 10 communication modes on the behavior of teams during co-operative problem-solving}},
year = {1974}
}
@article{Chen2010,
author = {Chen, David L and Mooney, Raymond J},
file = {:home/fduvalle/proj/mendeley/papers/Chen, Mooney - 2010 - Training a Multilingual Sportscaster Using Perceptual Context to Learn Language.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
title = {{Training a Multilingual Sportscaster: Using Perceptual Context to Learn Language}},
year = {2010}
}
@phdthesis{Kollar2011,
author = {Kollar, Thomas},
file = {:home/fduvalle/proj/mendeley/papers/Kollar - 2011 - Learning to Understand Spatial Language for Robotic Navigation and Mobile Manipulation.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
number = {2004},
school = {Massachusetts Institute of Technology},
title = {{Learning to Understand Spatial Language for Robotic Navigation and Mobile Manipulation}},
year = {2011}
}
@inproceedings{Bugmann2004,
author = {Bugmann, Guido and Klein, Ewan and Lauria, Stanislao and Kyriacou, Theocharis},
booktitle = {Intelligent Autonomous Systems},
file = {:home/fduvalle/proj/mendeley/papers/Bugmann et al. - 2004 - Corpus-Based Robotics A Route Instruction Example.pdf:pdf},
title = {{Corpus-Based Robotics: A Route Instruction Example}},
year = {2004}
}
@article{Krishnamurthy2013,
author = {Krishnamurthy, Jayant and Kollar, Thomas},
file = {:home/fduvalle/proj/mendeley/papers/Krishnamurthy, Kollar - 2013 - Jointly Learning to Parse and Perceive Connecting Natural Language to the Physical World.pdf:pdf},
journal = {Transactions of the Association for Computational Linguistics},
title = {{Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World}},
year = {2013}
}
@inproceedings{Cantrell2012,
author = {Cantrell, Rehj and Talamadupula, Kartik and Schermerhorn, Paul and Benton, J and Kambhampati, Subbarao and Scheutz, Matthias},
booktitle = {Human-Robot Interaction},
file = {:home/fduvalle/proj/mendeley/papers/Cantrell et al. - 2012 - Tell me when and why to do it! Run-time Planner Model Updates Via Natural Language Instruction.pdf:pdf},
title = {{Tell me when and why to do it! Run-time Planner Model Updates Via Natural Language Instruction}},
year = {2012}
}
@article{Lignos2014,
author = {Lignos, Constantine and Raman, Vasumathi and Finucane, Cameron and Marcus, Mitchell and Kress-Gazit, Hadas},
file = {:home/fduvalle/proj/mendeley/papers/Lignos et al. - 2014 - Provably correct reactive control from natural language.pdf:pdf},
journal = {Autonomous Robots},
title = {{Provably correct reactive control from natural language}},
year = {2014}
}
@inproceedings{Kollar2010,
abstract = {To be useful teammates to human partners, robots must be able to follow spoken instructions given in natural language. However, determining the correct sequence of actions in response to a set of spoken instructions is a complex decisionmaking problem. There is a ``semantic gap'' between the high-level symbolic models of the world that people use, and the low-level models of geometry, state dynamics, and perceptions that robots use. In this paper, we show how this gap can be bridged by inferring the best sequence of actions froma linguistic description and environmental features. This work improves upon previous work in three ways. First, by using a conditional random field (CRF), we learn the relative weight of environmental and linguistic features, enabling the system to learn the meanings of words and reducing the modeling effort in learning how to follow commands. Second, a number of long-range features are added, which help the system to use additional structure in the problem. Finally, given a natural language command, we infer both the referred path and landmark directly, thereby requiring the algorithm to pick a landmark by which it should navigate. The CRF is demonstrated to have 15\% error on a held-out dataset, when compared with 39\% error for a Markov random field (MRF). Finally, by analyzing the additional annotations necessary for this work, we find that natural language route directions map sequentially onto the corresponding path and landmarks 99.6\% of the time. In addition, the size of the referred landmark varies from 0m2 to 1964m2 and the length of the referred path varies from 0m to 40.83m.},
author = {Kollar, Thomas and Tellex, Stefanie and Roy, Nicholas},
booktitle = {AAAI Fall Symposium Series},
file = {:home/fduvalle/proj/mendeley/papers/Kollar, Tellex, Roy - 2010 - A Discriminative Model for Understanding Natural Language Route Directions.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{A Discriminative Model for Understanding Natural Language Route Directions}},
year = {2010}
}
@inproceedings{Shimizu2009,
author = {Shimizu, Nobuyuki and Haas, Andrew},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/fduvalle/proj/mendeley/papers//Shimizu, Haas - 2009 - Learning to follow navigational route instructions.pdf:pdf},
title = {{Learning to follow navigational route instructions}},
year = {2009}
}
@phdthesis{Chapman1990,
author = {Chapman, David},
file = {:home/fduvalle/proj/mendeley/papers/Chapman - 1990 - Vision, Instruction and Action.pdf:pdf},
school = {Massachusetts Institute of Technology},
title = {{Vision, Instruction and Action}},
year = {1990}
}
@article{Kyriacou2005,
abstract = {Humans who explain a task to a robot, or to another human, use chunks of actions that are often complex procedures for robots. An instructable robot needs to be able to map such chunks to existing pre-programmed primitives. We investigate the nature of these chunks in an urban visual navigation context and describe the implementation of one of the primitives: "take the n turn right/left". This implementation requires the use of a "short-lived" internal map updated as the robot moves along....},
author = {Kyriacou, Theocharis and Bugmann, Guido and Lauria, Stanislao},
file = {:home/fduvalle/proj/mendeley/papers/Kyriacou, Bugmann, Lauria - 2005 - Vision-based urban navigation procedures for verbally instructed robots.pdf:pdf},
institution = {University of Plymouth},
journal = {Robotics and Autonomous Systems},
publisher = {Elsevier},
title = {{Vision-based urban navigation procedures for verbally instructed robots}},
year = {2005}
}
@inproceedings{Skubic2004,
abstract = {In conversation, people often use spatial relationships to describe their environment, e.g., "There is a desk in front of me and a doorway behind it," and to issue directives, e.g., "go around the desk and through the doorway." In our research, we have been investigating the use of spatial relationships to establish a natural communication mechanism between people and robots, in particular, for novice users. In this paper, the work on robot spatial relationships is combined with a multimodal robot interface. We show how linguistic spatial descriptions and other spatial information can be extracted from an evidence grid map and how this information can be used in a natural, human-robot dialog. Examples using spatial language are included for both robot-to-human feedback and also human-to-robot commands. We also discuss some linguistic consequences in the semantic representations of spatial and locative information based on this work.},
author = {Skubic, Marjorie and Perzanowski, Dennis and Blisard, Samuel and Schultz, Alan and Adams, William and Bugajska, Magda and Brock, Derek},
booktitle = {Systems, Man, and Cybernetics},
file = {:home/fduvalle/proj/mendeley/papers/Skubic et al. - 2004 - Spatial language for human-robot dialogs.pdf:pdf},
keywords = {nlmmp},
mendeley-tags = {nlmmp},
title = {{Spatial language for human-robot dialogs}},
year = {2004}
}
@article{Anderson1991,
abstract = {Describes the corpus of unscripted task-oriented dialogues. Support of the study of spontaneous speech; Presentation of basic corpus statistics; Significance of linguistic and extralinguistic contexts.},
author = {Anderson, A and Bader, M and Bard, E and Boyle, E and Doherty, G M and Garrod, S and Isard, S and Kowtko, J and McAllister, J and Miller, J and Sotillo, C and Thompson, H S and Weinert, R},
journal = {Language and Speech},
publisher = {Association for Computational Linguistics},
title = {{The HCRC Map Task Corpus}},
year = {1991}
}
